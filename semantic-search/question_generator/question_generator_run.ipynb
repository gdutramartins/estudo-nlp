{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\r\n",
    "\r\n",
    "import torch\r\n",
    "\r\n",
    "from transformers import(\r\n",
    "    AutoModelForSeq2SeqLM, \r\n",
    "    AutoTokenizer,\r\n",
    "    PreTrainedModel,\r\n",
    "    PreTrainedTokenizer,\r\n",
    "    AutoConfig,\r\n",
    "    T5Tokenizer\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\git\\projetos-bi-master\\estudo-nlp\\semantic-search\\question_generator\\model\\t5-qg-tokenizer\n"
     ]
    }
   ],
   "source": [
    "MODEL_AND_TOKENIZER_PATH=os.path.join('model', 't5-small-qg-hl')\r\n",
    "TOKENIZER_PATH=os.path.join(os.getcwd(), 'model', 't5-qg-tokenizer')\r\n",
    "print(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E2EQGPipeline:\r\n",
    "    def __init__(\r\n",
    "        self,\r\n",
    "        model_path_or_name: str,\r\n",
    "        tokenizer_path_or_name: str,\r\n",
    "        use_cuda: bool\r\n",
    "    ) :\r\n",
    "\r\n",
    "        self.model:PreTrainedModel = AutoModelForSeq2SeqLM.from_pretrained(model_path_or_name)\r\n",
    "        \r\n",
    "        self.tokenizer:PreTrainedTokenizer = T5Tokenizer.from_pretrained(tokenizer_path_or_name, config=AutoConfig.from_pretrained(model_path_or_name))\r\n",
    "\r\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() and use_cuda else \"cpu\"\r\n",
    "        self.model.to(self.device)\r\n",
    "\r\n",
    "        assert self.model.__class__.__name__ in [\"T5ForConditionalGeneration\", \"BartForConditionalGeneration\"]\r\n",
    "        \r\n",
    "        if \"T5ForConditionalGeneration\" in self.model.__class__.__name__:\r\n",
    "            self.model_type = \"t5\"\r\n",
    "        else:\r\n",
    "            self.model_type = \"bart\"\r\n",
    "        \r\n",
    "        self.default_generate_kwargs = {\r\n",
    "            \"max_length\": 256,\r\n",
    "            \"num_beams\": 4,\r\n",
    "            \"length_penalty\": 1.5,\r\n",
    "            \"no_repeat_ngram_size\": 3,\r\n",
    "            \"early_stopping\": True,\r\n",
    "        }\r\n",
    "    \r\n",
    "    def __call__(self, context: str, **generate_kwargs):\r\n",
    "        inputs = self._prepare_inputs_for_e2e_qg(context)\r\n",
    "\r\n",
    "        # TODO: when overrding default_generate_kwargs all other arguments need to be passsed\r\n",
    "        # find a better way to do this\r\n",
    "        if not generate_kwargs:\r\n",
    "            generate_kwargs = self.default_generate_kwargs\r\n",
    "        \r\n",
    "        input_length = inputs[\"input_ids\"].shape[-1]\r\n",
    "        \r\n",
    "        # max_length = generate_kwargs.get(\"max_length\", 256)\r\n",
    "        # if input_length < max_length:\r\n",
    "        #     logger.warning(\r\n",
    "        #         \"Your max_length is set to {}, but you input_length is only {}. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\".format(\r\n",
    "        #             max_length, input_length\r\n",
    "        #         )\r\n",
    "        #     )\r\n",
    "\r\n",
    "        outs = self.model.generate(\r\n",
    "            input_ids=inputs['input_ids'].to(self.device), \r\n",
    "            attention_mask=inputs['attention_mask'].to(self.device),\r\n",
    "            **generate_kwargs\r\n",
    "        )\r\n",
    "\r\n",
    "        prediction = self.tokenizer.decode(outs[0], skip_special_tokens=True)\r\n",
    "        questions = prediction.split(\"<sep>\")\r\n",
    "        questions = [question.strip() for question in questions[:-1]]\r\n",
    "        return questions\r\n",
    "    \r\n",
    "    def _prepare_inputs_for_e2e_qg(self, context):\r\n",
    "        source_text = f\"generate questions: {context}\"\r\n",
    "        if self.model_type == \"t5\":\r\n",
    "            source_text = source_text + \" </s>\"\r\n",
    "        \r\n",
    "        inputs = self._tokenize([source_text], padding=False)\r\n",
    "        return inputs\r\n",
    "    \r\n",
    "    def _tokenize(\r\n",
    "        self,\r\n",
    "        inputs,\r\n",
    "        padding=True,\r\n",
    "        truncation=True,\r\n",
    "        add_special_tokens=True,\r\n",
    "        max_length=512\r\n",
    "    ):\r\n",
    "        inputs = self.tokenizer.batch_encode_plus(\r\n",
    "            inputs, \r\n",
    "            max_length=max_length,\r\n",
    "            add_special_tokens=add_special_tokens,\r\n",
    "            truncation=truncation,\r\n",
    "            padding=\"max_length\" if padding else False,\r\n",
    "            pad_to_max_length=padding,\r\n",
    "            return_tensors=\"pt\"\r\n",
    "        )\r\n",
    "        return inputs\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2e_qg = E2EQGPipeline(model_path_or_name=MODEL_AND_TOKENIZER_PATH,tokenizer_path_or_name=MODEL_AND_TOKENIZER_PATH,use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Python is an interpreted, high-level, general-purpose programming language. Created by Guido van Rossum \\\r\n",
    "and first released in 1991, Python's design philosophy emphasizes code \\\r\n",
    "readability with its notable use of significant whitespace.\"\r\n",
    "\r\n",
    "text2 = \"Gravity (from Latin gravitas, meaning 'weight'), or gravitation, is a natural phenomenon by which all \\\r\n",
    "things with mass or energy—including planets, stars, galaxies, and even light—are brought toward (or gravitate toward) \\\r\n",
    "one another. On Earth, gravity gives weight to physical objects, and the Moon's gravity causes the ocean tides. \\\r\n",
    "The gravitational attraction of the original gaseous matter present in the Universe caused it to begin coalescing \\\r\n",
    "and forming stars and caused the stars to group together into galaxies, so gravity is responsible for many of \\\r\n",
    "the large-scale structures in the Universe. Gravity has an infinite range, although its effects become increasingly \\\r\n",
    "weaker as objects get further away\"\r\n",
    "\r\n",
    "text3 = \"42 is the answer to life, universe and everything.\"\r\n",
    "\r\n",
    "text4 = \"Forrest Gump is a 1994 American comedy-drama film directed by Robert Zemeckis and written by Eric Roth. \\\r\n",
    "It is based on the 1986 novel of the same name by Winston Groom and stars Tom Hanks, Robin Wright, Gary Sinise, \\\r\n",
    "Mykelti Williamson and Sally Field. The story depicts several decades in the life of Forrest Gump (Hanks), \\\r\n",
    "a slow-witted but kind-hearted man from Alabama who witnesses and unwittingly influences several defining \\\r\n",
    "historical events in the 20th century United States. The film differs substantially from the novel.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gdutr\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:174: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What language is Python interpreted?',\n",
       " 'Who created Python?',\n",
       " 'When was Python first released?',\n",
       " \"What is Python's design philosophy?\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_qg(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gdutr\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:174: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is a natural phenomenon called gravitation?',\n",
       " 'What does gravity give weight to physical objects on Earth?']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_qg(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gdutr\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:174: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What is the answer to life, universe, and everything?',\n",
       " 'What is 42?',\n",
       " 'How is 42 the answer?']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_qg(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gdutr\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5.py:174: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Who is the director of Forrest Gump?',\n",
       " 'What is the name of the American comedy-drama film?']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2e_qg(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d98a242ac794090856e709806b29087f488f332a8741802de50a95a2014dd36b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('nlp-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}