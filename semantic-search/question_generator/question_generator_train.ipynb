{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "question-generator-train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('nlp-gpu': conda)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90fc4845a401438393e1aa432c460966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_75b7150776614b69b2c1a2662e84568f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_818a1d2d8b4c4026be1fa237dc994030",
              "IPY_MODEL_e98a5cc754d0467889f89e8e1249e7b1"
            ]
          }
        },
        "75b7150776614b69b2c1a2662e84568f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "818a1d2d8b4c4026be1fa237dc994030": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8ac0756a99d44cf9e36b261a7823823",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1197,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1197,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c23dae0c5a94def831944fbeb93dac0"
          }
        },
        "e98a5cc754d0467889f89e8e1249e7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2b55fccfd375480086bed47dba06d21e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 17.2kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae078eb270024154b9008f22957ef505"
          }
        },
        "c8ac0756a99d44cf9e36b261a7823823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c23dae0c5a94def831944fbeb93dac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b55fccfd375480086bed47dba06d21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae078eb270024154b9008f22957ef505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7e07ef31d9445348899400c223e390b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0243c82fa9884db19892bd95d289b398",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6542660d19f3496080891231fc7d3b95",
              "IPY_MODEL_64eed093b1214ff8b7cbb3c52f515819"
            ]
          }
        },
        "0243c82fa9884db19892bd95d289b398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6542660d19f3496080891231fc7d3b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0d542b9d2794679b0394e55bdf9f246",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 242065649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 242065649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5447b3006774feebffb0946074b8bbb"
          }
        },
        "64eed093b1214ff8b7cbb3c52f515819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b805c2b07a5b4e56ac34d4e0fae7015c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 242M/242M [00:07&lt;00:00, 30.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9cbf357ff5e04a25bb87822affd112d9"
          }
        },
        "e0d542b9d2794679b0394e55bdf9f246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5447b3006774feebffb0946074b8bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b805c2b07a5b4e56ac34d4e0fae7015c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9cbf357ff5e04a25bb87822affd112d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "interpreter": {
      "hash": "d98a242ac794090856e709806b29087f488f332a8741802de50a95a2014dd36b"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE8a3Dvqk1Qg",
        "outputId": "51e21b70-adf6-4cb0-b75b-e7da41b6c15d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72n3_4JOmLmM",
        "outputId": "a213dcfe-85ab-491d-bcec-578a93eb79a0"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install nlp\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: nlp in /usr/local/lib/python3.7/dist-packages (0.4.0)\n",
            "Requirement already satisfied: pyarrow>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from nlp) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from nlp) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from nlp) (1.19.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from nlp) (0.3.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from nlp) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from nlp) (3.0.12)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from nlp) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from nlp) (1.1.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->nlp) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->nlp) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->nlp) (1.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpLSA55gmQ89"
      },
      "source": [
        "import dataclasses\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    T5Tokenizer,\n",
        "    BartTokenizer,\n",
        "    HfArgumentParser,\n",
        "    DataCollator,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        "    Trainer\n",
        ")\n",
        "\n",
        "\n",
        "from data_collator import T2TDataCollator\n",
        "from utils import freeze_embeds, assert_not_all_frozen"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYs15FFtnAds"
      },
      "source": [
        "GDRIVE_PATH = '/content/drive/MyDrive'\n",
        "#TOKENIZER_PATH = os.path.join(GDRIVE_PATH, 'tokenizer/question-generator/t5_qg_tokenizer')\n",
        "TOKENIZER_PATH = os.path.join('model', 't5_qg_tokenizer')\n",
        "#DATASET_PATH = os.path.join(GDRIVE_PATH,'dataset', 'question-generator')\n",
        "DATASET_PATH = 'data'\n",
        "\n",
        "MODEL_TYPE_TO_TOKENIZER = {\n",
        "    \"t5\": T5Tokenizer,\n",
        "    \"bart\": BartTokenizer,\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NbrpjdGmW0f"
      },
      "source": [
        "@dataclass\n",
        "class ModelArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "    \"\"\"\n",
        "\n",
        "    model_name_or_path: str = field(\n",
        "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
        "    )\n",
        "    model_type: str = field(metadata={\"help\": \"One of 't5', 'bart'\"})\n",
        "    tokenizer_name_or_path: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
        "    )\n",
        "    cache_dir: Optional[str] = field(\n",
        "        default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
        "    )\n",
        "    label_smoothing: Optional[float] = field(\n",
        "        default=0,\n",
        "        metadata={\"help\": \"label smoothing rate, set to > 0 if you want to enable lable smoothing\"}\n",
        "    )\n",
        "    freeze_embeds: bool = field(\n",
        "        default=False,\n",
        "        metadata={\"help\": \"Freeze token embeddings and positional embeddings for bart, just token embeddings for t5.\"}\n",
        "    )"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2z4sTTZuN3j"
      },
      "source": [
        "@dataclass\n",
        "class DataTrainingArguments:\n",
        "    \"\"\"\n",
        "    Arguments pertaining to what data we are going to input our model for training and eval.\n",
        "    \"\"\"\n",
        "    train_file_path: str = field(\n",
        "        metadata={\"help\": \"Path for cached train dataset\"},\n",
        "    )\n",
        "    valid_file_path: str = field(\n",
        "        metadata={\"help\": \"Path for cached valid dataset\"},\n",
        "    )\n",
        "    data_dir: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Path for data files\"}, \n",
        "    )\n",
        "    task: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"Which task 'qa', 'qg', 'e2e_qg', 'ans_ext', 'multi'. 'multi' means 'qa', 'qg', 'ans_ext' tasks\"}, \n",
        "    )\n",
        "    qg_format: Optional[str] = field(\n",
        "        default='prepend_qg_format',\n",
        "        metadata={\"help\": \"How to format inputs for que generation, 'highlight_qg_format' or 'prepend_qg_format'\"}, \n",
        "    )\n",
        "    max_source_length: Optional[int] = field(\n",
        "        default=512,\n",
        "        metadata={\"help\": \"Max input length for the source text\"},\n",
        "    )\n",
        "    max_target_length: Optional[int] = field(\n",
        "        default=32,\n",
        "        metadata={\"help\": \"Max input length for the target text\"},\n",
        "    )"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QkenNksuVFu"
      },
      "source": [
        "args_dict = {\n",
        "    \"model_name_or_path\": \"t5-small\",\n",
        "    \"model_type\": \"t5\",\n",
        "    \"tokenizer_name_or_path\": \"t5_qg_tokenizer\",\n",
        "    \"output_dir\": \"t5-small-qg-hl\",\n",
        "    \"train_file_path\": \"data/train_data_qg_hl_t5.pt\",\n",
        "    \"valid_file_path\": \"data/valid_data_qg_hl_t5.pt\",\n",
        "    \"per_device_train_batch_size\": 32,\n",
        "    \"per_device_eval_batch_size\": 32,\n",
        "    \"gradient_accumulation_steps\": 8,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"num_train_epochs\": 10,\n",
        "    \"seed\": 42,\n",
        "    \"do_train\": True,\n",
        "    \"do_eval\": True,\n",
        "    \"evaluate_during_training\": True,\n",
        "    \"logging_steps\": 100    \n",
        "}\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ADxUTLC7_Sc"
      },
      "source": [
        "model_args = ModelArguments(\n",
        "    model_name_or_path=\"t5-small\",\n",
        "    model_type=\"t5\",\n",
        "    tokenizer_name_or_path=TOKENIZER_PATH\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwokIY8C7UhA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05643981-4399-49db-aa19-f013cee77bb5"
      },
      "source": [
        "# https://huggingface.co/transformers/_modules/transformers/training_args.html\n",
        "training_args= TrainingArguments(\n",
        "    per_device_eval_batch_size= 32,\n",
        "    gradient_accumulation_steps= 8,\n",
        "    learning_rate= 1e-4,\n",
        "    num_train_epochs= 10,\n",
        "    seed= 42,\n",
        "    do_train= True,\n",
        "    do_eval= True,\n",
        "    logging_steps= 100,\n",
        "    output_dir= 'model/t5-small-qg-hl',\n",
        "    prediction_loss_only=True,\n",
        "    label_smoothing_factor=model_args.label_smoothing\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "453lJel_7898"
      },
      "source": [
        "data_args = DataTrainingArguments(\n",
        "    train_file_path= os.path.join(DATASET_PATH,'train_data_e2e_qg_t5.pt'),\n",
        "    valid_file_path= os.path.join(DATASET_PATH,'valid_data_e2e_qg_t5.pt'),\n",
        "    task=\"e2e_qg\"\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsuqN_CDoUja"
      },
      "source": [
        " if (\n",
        "        os.path.exists(training_args.output_dir)\n",
        "        and os.listdir(training_args.output_dir)\n",
        "        and training_args.do_train\n",
        "        and not training_args.overwrite_output_dir\n",
        "    ):\n",
        "        raise ValueError(\n",
        "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"\n",
        "        )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVzLccyCsryW",
        "outputId": "41a0da57-5e43-4385-8dba-a4e467d8315a"
      },
      "source": [
        "# Setup logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "    level=logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN,\n",
        ")\n",
        "logger.warning(\n",
        "    \"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\",\n",
        "    training_args.local_rank,\n",
        "    training_args.device,\n",
        "    training_args.n_gpu,\n",
        "    bool(training_args.local_rank != -1),\n",
        "    training_args.fp16,\n",
        ")\n",
        "logger.info(\"Training/evaluation parameters %s\", training_args)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/28/2021 06:04:52 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "06/28/2021 06:04:52 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=model/t5-small-qg-hl, overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=False, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=True, per_device_train_batch_size=8, per_device_eval_batch_size=32, gradient_accumulation_steps=8, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs\\Jun28_06-04-24_Colosso-AI, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=100, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name=model/t5-small-qg-hl, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GQ7Am8Fs5-W"
      },
      "source": [
        "set_seed(training_args.seed)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "90fc4845a401438393e1aa432c460966",
            "75b7150776614b69b2c1a2662e84568f",
            "818a1d2d8b4c4026be1fa237dc994030",
            "e98a5cc754d0467889f89e8e1249e7b1",
            "c8ac0756a99d44cf9e36b261a7823823",
            "7c23dae0c5a94def831944fbeb93dac0",
            "2b55fccfd375480086bed47dba06d21e",
            "ae078eb270024154b9008f22957ef505",
            "a7e07ef31d9445348899400c223e390b",
            "0243c82fa9884db19892bd95d289b398",
            "6542660d19f3496080891231fc7d3b95",
            "64eed093b1214ff8b7cbb3c52f515819",
            "e0d542b9d2794679b0394e55bdf9f246",
            "d5447b3006774feebffb0946074b8bbb",
            "b805c2b07a5b4e56ac34d4e0fae7015c",
            "9cbf357ff5e04a25bb87822affd112d9"
          ]
        },
        "id": "tZILcdD9tQee",
        "outputId": "b9436e90-1335-4714-f04c-91a19c99b131"
      },
      "source": [
        "tokenizer_cls = MODEL_TYPE_TO_TOKENIZER[model_args.model_type]\n",
        "tokenizer = tokenizer_cls.from_pretrained(\n",
        "    model_args.tokenizer_name_or_path if model_args.tokenizer_name_or_path else model_args.model_name_or_path,\n",
        "    cache_dir=model_args.cache_dir,\n",
        ")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_args.model_name_or_path,\n",
        "    cache_dir=model_args.cache_dir,\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/28/2021 06:05:15 - INFO - filelock -   Lock 1861264265520 acquired on C:\\Users\\gdutr/.cache\\huggingface\\transformers\\fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985.lock\n",
            "Downloading: 100%|██████████| 1.20k/1.20k [00:00<00:00, 1.20MB/s]\n",
            "06/28/2021 06:05:15 - INFO - filelock -   Lock 1861264265520 released on C:\\Users\\gdutr/.cache\\huggingface\\transformers\\fe501e8fd6425b8ec93df37767fcce78ce626e34cc5edc859c662350cf712e41.406701565c0afd9899544c1cb8b93185a76f00b31e5ce7f6e18bbaef02241985.lock\n",
            "06/28/2021 06:05:16 - INFO - filelock -   Lock 1861264265520 acquired on C:\\Users\\gdutr/.cache\\huggingface\\transformers\\fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885.lock\n",
            "Downloading: 100%|██████████| 242M/242M [00:21<00:00, 11.1MB/s]\n",
            "06/28/2021 06:05:38 - INFO - filelock -   Lock 1861264265520 released on C:\\Users\\gdutr/.cache\\huggingface\\transformers\\fee5a3a0ae379232608b6eed45d2d7a0d2966b9683728838412caccc41b4b0ed.ddacdc89ec88482db20c676f0861a336f3d0409f94748c209847b49529d73885.lock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj-mze2cucoY",
        "outputId": "f21255eb-a591-45e7-92a1-9707b4061957"
      },
      "source": [
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32102, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Cw9WjdDuhBx",
        "outputId": "05be72d5-fe70-4375-ed2f-357b78043613"
      },
      "source": [
        "if model_args.freeze_embeds:\n",
        "        logger.info(\"freezing embeddings of the model\")\n",
        "        freeze_embeds(model)\n",
        "        assert_not_all_frozen(model)\n",
        "\n",
        "# Get datasets\n",
        "logger.info('loading dataset')\n",
        "\n",
        "train_dataset = torch.load(data_args.train_file_path) if training_args.do_train else None\n",
        "valid_dataset = torch.load(data_args.valid_file_path) if training_args.do_eval else None\n",
        "\n",
        "logger.info('finished loading dataset')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "06/28/2021 06:09:54 - INFO - __main__ -   loading dataset\n",
            "06/28/2021 06:09:54 - INFO - nlp.utils.file_utils -   PyTorch version 1.8.1 available.\n",
            "06/28/2021 06:09:54 - INFO - nlp.utils.file_utils -   TensorFlow version 2.4.0 available.\n",
            "06/28/2021 06:09:55 - INFO - __main__ -   finished loading dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMesOUcDurKV"
      },
      "source": [
        "# Initialize data_collator\n",
        "data_collator = T2TDataCollator(\n",
        "    tokenizer=tokenizer,\n",
        "    model_type=model_args.model_type,\n",
        "    mode=\"training\",\n",
        "    using_tpu=training_args.tpu_num_cores is not None\n",
        ")\n",
        "\n",
        "# Initialize our Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    data_collator=data_collator\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "zg6xxwJSu3jR",
        "outputId": "a2b240f2-2baa-4b07-b997-6a6b375ef0dc"
      },
      "source": [
        "# Training\n",
        "if training_args.do_train:\n",
        "    trainer.train(\n",
        "        model_path=model_args.model_name_or_path if os.path.isdir(model_args.model_name_or_path) else None\n",
        "    )\n",
        "    trainer.save_model()\n",
        "    # For convenience, we also re-save the tokenizer to the same directory,\n",
        "    # so that you can share your model easily on huggingface.co/models =)\n",
        "    if trainer.is_world_process_zero():\n",
        "        tokenizer.save_pretrained(training_args.output_dir)\n",
        "\n",
        "# Evaluation\n",
        "results = {}\n",
        "if training_args.do_eval and training_args.local_rank in [-1, 0]:\n",
        "    logger.info(\"*** Evaluate ***\")\n",
        "\n",
        "    eval_output = trainer.evaluate()\n",
        "\n",
        "    output_eval_file = os.path.join(training_args.output_dir, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results *****\")\n",
        "        for key in sorted(eval_output.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(eval_output[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(eval_output[key])))\n",
        "\n",
        "    results.update(eval_output)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\gdutr\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\transformers\\trainer.py:833: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\n",
            "  warnings.warn(\n",
            "  3%|▎         | 100/2950 [01:18<35:21,  1.34it/s]{'loss': 3.7416, 'learning_rate': 9.661016949152543e-05, 'epoch': 0.34}\n",
            "  7%|▋         | 200/2950 [02:37<37:19,  1.23it/s]{'loss': 2.6594, 'learning_rate': 9.322033898305085e-05, 'epoch': 0.68}\n",
            " 10%|█         | 300/2950 [03:56<33:42,  1.31it/s]{'loss': 2.5182, 'learning_rate': 8.983050847457629e-05, 'epoch': 1.02}\n",
            " 14%|█▎        | 400/2950 [05:15<32:23,  1.31it/s]{'loss': 2.4076, 'learning_rate': 8.644067796610171e-05, 'epoch': 1.36}\n",
            " 17%|█▋        | 500/2950 [06:34<32:13,  1.27it/s]{'loss': 2.3598, 'learning_rate': 8.305084745762712e-05, 'epoch': 1.69}\n",
            " 20%|██        | 600/2950 [07:53<30:45,  1.27it/s]{'loss': 2.3152, 'learning_rate': 7.966101694915254e-05, 'epoch': 2.03}\n",
            " 24%|██▎       | 700/2950 [09:13<30:29,  1.23it/s]{'loss': 2.2555, 'learning_rate': 7.627118644067796e-05, 'epoch': 2.37}\n",
            " 27%|██▋       | 800/2950 [10:31<29:48,  1.20it/s]{'loss': 2.2309, 'learning_rate': 7.288135593220338e-05, 'epoch': 2.71}\n",
            " 31%|███       | 900/2950 [11:49<26:35,  1.28it/s]{'loss': 2.1998, 'learning_rate': 6.949152542372882e-05, 'epoch': 3.05}\n",
            " 34%|███▍      | 1000/2950 [13:08<25:12,  1.29it/s]{'loss': 2.1764, 'learning_rate': 6.610169491525424e-05, 'epoch': 3.39}\n",
            " 37%|███▋      | 1100/2950 [14:27<23:53,  1.29it/s]{'loss': 2.1478, 'learning_rate': 6.271186440677966e-05, 'epoch': 3.73}\n",
            " 41%|████      | 1200/2950 [15:47<23:24,  1.25it/s]{'loss': 2.139, 'learning_rate': 5.932203389830509e-05, 'epoch': 4.07}\n",
            " 44%|████▍     | 1300/2950 [17:05<22:03,  1.25it/s]{'loss': 2.1119, 'learning_rate': 5.593220338983051e-05, 'epoch': 4.41}\n",
            " 47%|████▋     | 1400/2950 [18:24<20:31,  1.26it/s]{'loss': 2.0856, 'learning_rate': 5.254237288135594e-05, 'epoch': 4.75}\n",
            " 51%|█████     | 1500/2950 [19:43<19:24,  1.25it/s]{'loss': 2.0922, 'learning_rate': 4.915254237288136e-05, 'epoch': 5.08}\n",
            " 54%|█████▍    | 1600/2950 [21:03<18:13,  1.23it/s]{'loss': 2.0488, 'learning_rate': 4.5762711864406784e-05, 'epoch': 5.42}\n",
            " 58%|█████▊    | 1700/2950 [22:23<17:02,  1.22it/s]{'loss': 2.0542, 'learning_rate': 4.2372881355932206e-05, 'epoch': 5.76}\n",
            " 61%|██████    | 1800/2950 [23:42<14:58,  1.28it/s]{'loss': 2.0607, 'learning_rate': 3.898305084745763e-05, 'epoch': 6.1}\n",
            " 64%|██████▍   | 1900/2950 [25:02<13:47,  1.27it/s]{'loss': 2.011, 'learning_rate': 3.559322033898305e-05, 'epoch': 6.44}\n",
            " 68%|██████▊   | 2000/2950 [26:21<12:06,  1.31it/s]{'loss': 2.0194, 'learning_rate': 3.2203389830508473e-05, 'epoch': 6.78}\n",
            " 71%|███████   | 2100/2950 [27:41<11:18,  1.25it/s]{'loss': 2.0248, 'learning_rate': 2.88135593220339e-05, 'epoch': 7.12}\n",
            " 75%|███████▍  | 2200/2950 [29:00<10:00,  1.25it/s]{'loss': 1.9998, 'learning_rate': 2.5423728813559322e-05, 'epoch': 7.46}\n",
            " 78%|███████▊  | 2300/2950 [30:19<08:43,  1.24it/s]{'loss': 2.0049, 'learning_rate': 2.2033898305084748e-05, 'epoch': 7.8}\n",
            " 81%|████████▏ | 2400/2950 [31:35<07:03,  1.30it/s]{'loss': 2.0006, 'learning_rate': 1.864406779661017e-05, 'epoch': 8.14}\n",
            " 85%|████████▍ | 2500/2950 [32:52<05:40,  1.32it/s]{'loss': 1.9798, 'learning_rate': 1.5254237288135596e-05, 'epoch': 8.47}\n",
            " 88%|████████▊ | 2600/2950 [34:10<04:25,  1.32it/s]{'loss': 1.9823, 'learning_rate': 1.1864406779661018e-05, 'epoch': 8.81}\n",
            " 92%|█████████▏| 2700/2950 [35:26<03:10,  1.31it/s]{'loss': 1.9822, 'learning_rate': 8.47457627118644e-06, 'epoch': 9.15}\n",
            " 95%|█████████▍| 2800/2950 [36:43<01:51,  1.34it/s]{'loss': 1.9744, 'learning_rate': 5.084745762711865e-06, 'epoch': 9.49}\n",
            " 98%|█████████▊| 2900/2950 [37:59<00:39,  1.26it/s]{'loss': 1.9678, 'learning_rate': 1.6949152542372882e-06, 'epoch': 9.83}\n",
            "100%|██████████| 2950/2950 [38:38<00:00,  1.27it/s]\n",
            "{'train_runtime': 2318.9587, 'train_samples_per_second': 1.272, 'epoch': 10.0}\n",
            "06/28/2021 06:49:39 - INFO - __main__ -   *** Evaluate ***\n",
            "100%|██████████| 65/65 [00:08<00:00,  7.63it/s]\n",
            "06/28/2021 06:49:48 - INFO - __main__ -   ***** Eval results *****\n",
            "06/28/2021 06:49:48 - INFO - __main__ -     epoch = 10.0\n",
            "06/28/2021 06:49:48 - INFO - __main__ -     eval_loss = 1.8666026592254639\n",
            "06/28/2021 06:49:48 - INFO - __main__ -     eval_mem_cpu_alloc_delta = 226281\n",
            "06/28/2021 06:49:48 - INFO - __main__ -     eval_mem_cpu_peaked_delta = 205585\n",
            "06/28/2021 06:49:48 - INFO - __main__ -     eval_mem_gpu_alloc_delta = 0\n",
            "06/28/2021 06:49:48 - INFO - __main__ -     eval_mem_gpu_peaked_delta = 1074092032\n",
            "06/28/2021 06:49:48 - INFO - __main__ -     eval_runtime = 8.732\n",
            "06/28/2021 06:49:48 - INFO - __main__ -     eval_samples_per_second = 236.715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY3JfPOXzqQn"
      },
      "source": [
        "print(results)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.8666026592254639, 'eval_runtime': 8.732, 'eval_samples_per_second': 236.715, 'epoch': 10.0, 'eval_mem_cpu_alloc_delta': 226281, 'eval_mem_gpu_alloc_delta': 0, 'eval_mem_cpu_peaked_delta': 205585, 'eval_mem_gpu_peaked_delta': 1074092032}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHX1LrCtz3XT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}